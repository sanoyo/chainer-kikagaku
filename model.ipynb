{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanoyoh/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/_environment_check.py:38: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Also note that Chainer does not officially support Mac OS X.\n",
      "Please use it at your own risk.\n",
      "\n",
      "  ''')  # NOQA\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(chainer.Chain):\n",
    "    \n",
    "    # モデルの構造\n",
    "    def __init__(self, n_mid_units1=10, n_mid_units2=5, n_out=3):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            # None →　chainer側で勝手に読み取ってくれる\n",
    "            self.fc1 = L.Linear(None, n_mid_units1)\n",
    "            self.fc2 = L.Linear(None, n_mid_units2)\n",
    "            self.fc3 = L.Linear(None, n_out)\n",
    "            # BatchNormalization\n",
    "            self.bn = L.BatchNormalization(10)\n",
    "            \n",
    "    # 順伝播\n",
    "    def __call__(self, x):\n",
    "        # 変数を上書きしていく\n",
    "        h = self.bn(x)\n",
    "        h = self.fc1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "nn = NN()\n",
    "model = L.Classifier(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習するための設定\n",
    "### Optimizerの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = chainer.optimizers.Adam() # 確率的勾配降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0x10d6ea5f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratorの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('wine-class.csv')\n",
    "t = df.iloc[:, 0]\n",
    "x = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.values -1\n",
    "x = x.values\n",
    "\n",
    "x = x. astype('f')\n",
    "t = t. astype('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(x, t))\n",
    "n_train = int(len(dataset)*0.7)\n",
    "train, test = chainer.datasets.split_dataset_random(dataset, n_train, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updaterの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# CPU : -1\n",
    "# GPU : 0\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainerとExtensionsの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainerの宣言\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result/wine')\n",
    "\n",
    "# 検証データで評価\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "\n",
    "# 1エポックごとに(trigger)にtrainデータに対するloss・accuracyとtestデータに対するloss・accuracy、経過時間を出力します\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.338462       0.341667                  11.3522     5.08828               0.118278      \n",
      "\u001b[J2           0.466667       0.675                     4.94452     1.68124               0.232575      \n",
      "\u001b[J3           0.661538       0.616667                  1.22626     0.823669              0.311839      \n",
      "\u001b[J4           0.7            0.6                       0.862125    0.857965              0.382448      \n",
      "\u001b[J5           0.666667       0.6                       0.883349    0.857521              0.452386      \n",
      "\u001b[J6           0.669231       0.616667                  0.883131    0.836601              0.530505      \n",
      "\u001b[J7           0.666667       0.616667                  0.861231    0.811822              0.609342      \n",
      "\u001b[J8           0.684615       0.616667                  0.846968    0.822331              0.681252      \n",
      "\u001b[J9           0.641667       0.6                       0.857494    0.833789              0.746402      \n",
      "\u001b[J10          0.691667       0.6                       0.843183    0.824105              0.807628      \n",
      "\u001b[J11          0.669231       0.616667                  0.838478    0.810355              0.877456      \n",
      "\u001b[J12          0.675          0.616667                  0.852087    0.803773              0.960006      \n",
      "\u001b[J13          0.684615       0.616667                  0.834443    0.805726              1.0452        \n",
      "\u001b[J14          0.666667       0.616667                  0.84794     0.800486              1.13491       \n",
      "\u001b[J15          0.691667       0.616667                  0.825498    0.801109              1.20016       \n",
      "\u001b[J16          0.684615       0.616667                  0.843323    0.793917              1.26779       \n",
      "\u001b[J17          0.691667       0.616667                  0.816977    0.788281              1.33935       \n",
      "\u001b[J18          0.707692       0.616667                  0.84062     0.788686              1.44604       \n",
      "\u001b[J19          0.666667       0.616667                  0.817556    0.786346              1.52204       \n",
      "\u001b[J20          0.691667       0.616667                  0.820383    0.795458              1.59866       \n",
      "\u001b[J21          0.646154       0.616667                  0.826137    0.8047                1.68773       \n",
      "\u001b[J22          0.7            0.6                       0.801146    0.805905              1.75585       \n",
      "\u001b[J23          0.669231       0.6                       0.825803    0.805637              1.82842       \n",
      "\u001b[J24          0.65           0.6                       0.816778    0.806002              1.89879       \n",
      "\u001b[J25          0.7            0.616667                  0.792132    0.77461               1.98197       \n",
      "\u001b[J26          0.692308       0.633333                  0.78829     0.768397              2.08078       \n",
      "\u001b[J27          0.691667       0.616667                  0.822259    0.770862              2.16481       \n",
      "\u001b[J28          0.669231       0.6                       0.806554    0.80066               2.23828       \n",
      "\u001b[J29          0.658333       0.616667                  0.82979     0.771328              2.31017       \n",
      "\u001b[J30          0.683333       0.616667                  0.79852     0.767271              2.38771       \n",
      "\u001b[J31          0.684615       0.616667                  0.78306     0.763687              2.45651       \n",
      "\u001b[J32          0.7            0.616667                  0.795456    0.763074              2.53019       \n",
      "\u001b[J33          0.7            0.616667                  0.790238    0.762728              2.59859       \n",
      "\u001b[J34          0.658333       0.6                       0.794881    0.788887              2.66729       \n",
      "\u001b[J35          0.675          0.616667                  0.789787    0.763044              2.73326       \n",
      "\u001b[J36          0.684615       0.616667                  0.778966    0.754904              2.79945       \n",
      "\u001b[J37          0.683333       0.616667                  0.791086    0.759819              2.86696       \n",
      "\u001b[J38          0.669231       0.616667                  0.774013    0.756892              2.94124       \n",
      "\u001b[J39          0.675          0.616667                  0.793423    0.752583              3.01067       \n",
      "\u001b[J40          0.691667       0.616667                  0.781929    0.749563              3.12364       \n",
      "\u001b[J41          0.676923       0.616667                  0.761317    0.755607              3.23534       \n",
      "\u001b[J42          0.675          0.616667                  0.781439    0.754156              3.34032       \n",
      "\u001b[J43          0.646154       0.6                       0.789885    0.77781               3.44953       \n",
      "\u001b[J44          0.666667       0.616667                  0.766703    0.765394              3.55011       \n",
      "\u001b[J45          0.683333       0.6                       0.771302    0.768125              3.6608        \n",
      "\u001b[J46          0.669231       0.616667                  0.772638    0.76618               3.73789       \n",
      "\u001b[J47          0.691667       0.6                       0.759593    0.768652              3.8044        \n",
      "\u001b[J48          0.676923       0.633333                  0.766124    0.754195              3.89498       \n",
      "\u001b[J49          0.658333       0.616667                  0.772697    0.742372              3.96419       \n",
      "\u001b[J50          0.691667       0.616667                  0.752008    0.741495              4.03273       \n",
      "\u001b[J51          0.676923       0.616667                  0.773018    0.738404              4.108         \n",
      "\u001b[J52          0.683333       0.633333                  0.74878     0.751239              4.18013       \n",
      "\u001b[J53          0.692308       0.616667                  0.764865    0.736362              4.26368       \n",
      "\u001b[J54          0.658333       0.6                       0.787031    0.773814              4.3332        \n",
      "\u001b[J55          0.65           0.6                       0.782273    0.760035              4.41079       \n",
      "\u001b[J56          0.669231       0.633333                  0.786513    0.730641              4.48765       \n",
      "\u001b[J57          0.675          0.616667                  0.76563     0.731248              4.5575        \n",
      "\u001b[J58          0.7            0.616667                  0.732442    0.73367               4.63306       \n",
      "\u001b[J59          0.658333       0.616667                  0.808338    0.730589              4.70033       \n",
      "\u001b[J60          0.65           0.6                       0.782004    0.780286              4.77101       \n",
      "\u001b[J61          0.638462       0.633333                  0.790442    0.745195              4.86321       \n",
      "\u001b[J62          0.708333       0.633333                  0.718358    0.725939              4.92997       \n",
      "\u001b[J63          0.7            0.616667                  0.735615    0.728421              5.0066        \n",
      "\u001b[J64          0.608333       0.6                       0.827239    0.767963              5.0783        \n",
      "\u001b[J65          0.691667       0.616667                  0.734594    0.726924              5.22934       \n",
      "\u001b[J66          0.684615       0.616667                  0.758872    0.726204              5.34456       \n",
      "\u001b[J67          0.683333       0.616667                  0.742101    0.742751              5.51522       \n",
      "\u001b[J68          0.661538       0.633333                  0.734504    0.736576              5.61246       \n",
      "\u001b[J69          0.658333       0.616667                  0.754918    0.723691              5.69997       \n",
      "\u001b[J70          0.7            0.633333                  0.731563    0.729952              5.80869       \n",
      "\u001b[J71          0.676923       0.616667                  0.718121    0.722458              5.93356       \n",
      "\u001b[J72          0.683333       0.616667                  0.735535    0.720595              6.0148        \n",
      "\u001b[J73          0.676923       0.616667                  0.730829    0.72031               6.09228       \n",
      "\u001b[J74          0.675          0.616667                  0.730197    0.724582              6.16998       \n",
      "\u001b[J75          0.658333       0.616667                  0.727206    0.723939              6.23828       \n",
      "\u001b[J76          0.692308       0.616667                  0.783875    0.71908               6.31852       \n",
      "\u001b[J77          0.658333       0.6                       0.720635    0.750429              6.39244       \n",
      "\u001b[J78          0.684615       0.616667                  0.735668    0.717542              6.47241       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J79          0.666667       0.616667                  0.75631     0.717537              6.54524       \n",
      "\u001b[J80          0.683333       0.633333                  0.725883    0.720225              6.62314       \n",
      "\u001b[J81          0.661538       0.616667                  0.723444    0.713392              6.69964       \n",
      "\u001b[J82          0.675          0.616667                  0.732459    0.716307              6.78385       \n",
      "\u001b[J83          0.661538       0.616667                  0.749685    0.717628              6.89718       \n",
      "\u001b[J84          0.7            0.616667                  0.695926    0.714322              7.01797       \n",
      "\u001b[J85          0.683333       0.616667                  0.72868     0.711305              7.09819       \n",
      "\u001b[J86          0.669231       0.633333                  0.715179    0.722697              7.18976       \n",
      "\u001b[J87          0.691667       0.616667                  0.705637    0.715389              7.2691        \n",
      "\u001b[J88          0.692308       0.616667                  0.697344    0.71197               7.34022       \n",
      "\u001b[J89          0.666667       0.633333                  0.739292    0.725791              7.40953       \n",
      "\u001b[J90          0.683333       0.633333                  0.721512    0.708298              7.47555       \n",
      "\u001b[J91          0.653846       0.616667                  0.722458    0.711532              7.55676       \n",
      "\u001b[J92          0.7            0.616667                  0.702429    0.710546              7.68029       \n",
      "\u001b[J93          0.676923       0.616667                  0.718427    0.710958              7.78356       \n",
      "\u001b[J94          0.708333       0.6                       0.687262    0.728835              7.87704       \n",
      "\u001b[J95          0.666667       0.616667                  0.71402     0.709124              7.94661       \n",
      "\u001b[J96          0.692308       0.616667                  0.699936    0.70785               8.03351       \n",
      "\u001b[J97          0.683333       0.616667                  0.705664    0.706969              8.10111       \n",
      "\u001b[J98          0.7            0.633333                  0.702844    0.704315              8.18359       \n",
      "\u001b[J99          0.666667       0.633333                  0.707947    0.710027              8.29129       \n",
      "\u001b[J100         0.7            0.616667                  0.689146    0.709975              8.39389       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/wine/log') as f:\n",
    "    logs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>main/accuracy</th>\n",
       "      <th>main/loss</th>\n",
       "      <th>validation/main/accuracy</th>\n",
       "      <th>validation/main/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118278</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>11.352243</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>5.088283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232575</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>4.944518</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1.681242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311839</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>1.226263</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.823669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.382448</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.862125</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452386</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.883349</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elapsed_time  epoch  iteration  main/accuracy  main/loss  \\\n",
       "0      0.118278      1         13       0.338462  11.352243   \n",
       "1      0.232575      2         25       0.466667   4.944518   \n",
       "2      0.311839      3         38       0.661538   1.226263   \n",
       "3      0.382448      4         50       0.700000   0.862125   \n",
       "4      0.452386      5         62       0.666667   0.883349   \n",
       "\n",
       "   validation/main/accuracy  validation/main/loss  \n",
       "0                  0.341667              5.088283  \n",
       "1                  0.675000              1.681242  \n",
       "2                  0.616667              0.823669  \n",
       "3                  0.600000              0.857965  \n",
       "4                  0.600000              0.857521  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# results[['main/accuracy', 'validation/main/accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済モデルを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainer.serializers.save_npz('models/wine.npz', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済モデルを使用した推論(予測値の計算)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済モデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの構造明示\n",
    "model = L.Classifier(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainer.serializers.load_npz('models/wine.npz', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測値の計算\n",
    "今回は一番最初のサンプルに対する予測値の計算を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = x[0]\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidType",
     "evalue": "\nInvalid operation is performed in: BatchNormalization (Forward)\n\nExpect: in_types[0].ndim >= in_types[1].ndim + 1\nActual: 1 < 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidType\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-91bf9a21725f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 予測値の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# (バッチサイズ、入力変数の数)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-cdcb5b79f3f4>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 変数を上書きしていく\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/links/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m             ret = functions.batch_normalization(\n\u001b[1;32m    207\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 running_var=self.avg_var, decay=decay)\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# Use running average statistics or fine-tuned statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(x, gamma, beta, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     return BatchNormalization(eps, running_mean, running_var, decay).apply(\n\u001b[0;32m--> 718\u001b[0;31m         (x, gamma, beta))[0]\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[0;34m(self, in_data)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0min_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_types'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_check_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[0;34m(self, in_types)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgamma_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbeta_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgamma_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbeta_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/utils/type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(*bool_exprs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbool_exprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/utils/type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m             raise InvalidType(\n\u001b[1;32m    481\u001b[0m                 \u001b[0;34m'{0} {1} {2}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 '{0} {1} {2}'.format(left, self.inv, right))\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidType\u001b[0m: \nInvalid operation is performed in: BatchNormalization (Forward)\n\nExpect: in_types[0].ndim >= in_types[1].ndim + 1\nActual: 1 < 2"
     ]
    }
   ],
   "source": [
    "# 予測値の計算\n",
    "# (バッチサイズ、入力変数の数)\n",
    "y = model.predictor(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_new[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanoyoh/Desktop/latest_tech/computer_vision/chainer/3env-chainer/lib/python3.6/site-packages/chainer/functions/normalization/batch_normalization.py:67: UserWarning: A batch with no more than one sample has been given to F.batch_normalization. F.batch_normalization will always output a zero tensor for such batches. This could be caused by incorrect configuration in your code (such as running evaluation while chainer.config.train=True), but could also happen in the last batch of training if non-repeating iterator is used.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "y = model.predictor(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 2.3804693, -2.1527495,  1.3052889]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[0.7396548 , 0.00794835, 0.25239697]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上記をたして1になるようにする\n",
    "y = F.softmax(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7396548 , 0.00794835, 0.25239697]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
